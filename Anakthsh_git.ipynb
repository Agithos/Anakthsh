{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agithos/Anakthsh/blob/main/Anakthsh_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9uZmznUQghR"
      },
      "source": [
        "### ΛΕΙΤΟΥΡΓΙΑ SCRIPT\n",
        "---\n",
        "###Βήματα λειτουργίας\n",
        "* Ctrl+F9 (Run All cells)\n",
        "* Copy-paste σε Browser το URL του ngrok web-server\n",
        "  * Αυτό που γράφει δηλαδή \"Running on *****.ngrok.io\"\n",
        "  * Σε Chrome πρέπει να είναι σε Private mode. Αλλιώς, Mozilla\n",
        "---\n",
        "###Επιλογές συγκεκριμένης λύσης\n",
        "* Ανακτώ από τα πρώτα 60 links για οικονομία χρόνου.  (δηλαδή με anakthsh(links,60) )\n",
        "* Μπορώ να ανακτήσω από όλα τα links αν αλλάξω σε anakthsh(links,0)\n",
        "\n",
        "#### Λογική ανάκτησης ερωτήσεων\n",
        "* Όλη η ερώτηση βρίσκεται μέσα σε \\<strong>\n",
        "  * Αν υπάρχει μέρος που δεν είναι μέσα σε \\<strong>, θα είναι bold μέρος μιας απάντησης\n",
        "* Τελευταίο char της ερώτησης, αφού έχω καθαρίσει με .strip() είναι '?'\n",
        "\n",
        "#### Ποια questions έχει ανακτήσει\n",
        "* li μέσα σε Order list\n",
        "* p με \\<strong> να κάνει wrap την Ερώτηση\n",
        "  * Ή διαδοχικά \\<strong>\n",
        "* h3 για κάθε ερώτηση\n",
        "\n",
        "---\n",
        "#### Παραδείγματα Queries\n",
        "* Act of Europe?\n",
        "* Economy of Europe \n",
        "* Ukraine actions\n",
        "\n",
        "\n",
        "####Πιθανά προβλήματα\n",
        "* Φαίνονται στο τέλος του Notebook. Πιο πιθανά όταν σταματάει και ξαναξεκινάει ο ngrok-server\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTwvBqbuagAW"
      },
      "source": [
        "### Pip installs και κατεβασμα elastic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMoivI3kN789"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "apt install chromium-chromedriver\n",
        "pip install beautifulsoup4\n",
        "pip install selenium\n",
        "pip install farm-haystack\n",
        "\n",
        "pip install pyngrok==4.1.1\n",
        "pip install flask-ngrok\n",
        "\n",
        "git clone \"https://github.com/Agithos/Anakthsh.git\"\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "# rm -rf Anakthsh\n",
        "# rm -rf elasticsearch-7.9.2/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrokToken = \"\" #@param {type:\"string\"}\n",
        "!ngrok authtoken $ngrokToken"
      ],
      "metadata": {
        "id": "ca9AqlzD__nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Init haystack, elastic server και selenium browser"
      ],
      "metadata": {
        "id": "Ej4U-p0rONdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlgCvVowOHaJ"
      },
      "outputs": [],
      "source": [
        "## INIT ##\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import time\n",
        "import re\n",
        "import math\n",
        "import os\n",
        "from subprocess import Popen,PIPE,STDOUT\n",
        "\n",
        "from haystack.nodes import EmbeddingRetriever\n",
        "from haystack.nodes import ElasticsearchRetriever\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "from haystack.document_stores import elasticsearch_index_to_document_store\n",
        "from haystack.pipelines import FAQPipeline\n",
        "\n",
        "es_server = Popen(\n",
        "    [\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1)\n",
        ")\n",
        "!sleep 30\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "browser = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "\n",
        "baseURL = \"https://ec.europa.eu/commission/presscorner/\"\n",
        "startURL = \"https://ec.europa.eu/commission/presscorner/advancedsearch/en?keywords=&dotyp=852&parea=0&pareaType=0&datepickerbefore=&datebefore=&commissioner=&datepickerafter=&dateafter=&pagenumber=\"\n",
        "links = []\n",
        "pattern = \"<\\/question>\\s*(?:<\\/\\w*>\\s*)*([\\s\\S]*?)\\s*(?:<\\w*>\\s*)*<question[\\s\\S]*?>\"\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(\n",
        "  username=\"\",\n",
        "  password=\"\",\n",
        "  similarity=\"cosine\",\n",
        "  embedding_field=\"question_emb\",\n",
        "  index=\"document\",\n",
        "  embedding_dim=384)\n",
        "\n",
        "model = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "retrieverElastic = ElasticsearchRetriever(document_store)\n",
        "retrieverEmbedding = EmbeddingRetriever(\n",
        "  document_store=document_store,\n",
        "  embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "  use_gpu=True)\n",
        "\n",
        "pipeEmbedding = FAQPipeline(retriever = retrieverEmbedding)\n",
        "pipeElastic = FAQPipeline(retriever = retrieverElastic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions "
      ],
      "metadata": {
        "id": "Yt0pzw2wOWiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrPT-6EwTDrx"
      },
      "outputs": [],
      "source": [
        "## FUNCTIONS ##\n",
        "\n",
        "def anakthsh(links, linkNo):\n",
        "  pagesLimit = math.ceil(linkNo/10)\n",
        "  if pagesLimit==1:       # to elaxisto i findAllPageLinks katevazei 2 selides\n",
        "    pagesLimit = 2\n",
        "  findAllPageLinks(links, pagesLimit)\n",
        "  if (linkNo == 0):\n",
        "    downloadLinkInfo(links)\n",
        "  else:\n",
        "    downloadLinkInfo(links[:linkNo])\n",
        "\n",
        "# Soup gia opoio url exw\n",
        "def makeSoup (url):\n",
        "    browser.get(url)\n",
        "    time.sleep(5)\n",
        "    soup = BeautifulSoup(browser.page_source)\n",
        "    return soup\n",
        "\n",
        "def isNextPage(soup):\n",
        "  nextButton = soup.select('a[title=\"Go to next page\"]')\n",
        "  if (nextButton):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# MAIN1: Find Links\n",
        "def findAllPageLinks(links, limit):\n",
        "  soup = makeSoup(startURL)\n",
        "  getCurrentPageLinks(soup, links)\n",
        "  # oso exei nextPage\n",
        "  pageNumber = 2\n",
        "  while(isNextPage(soup)):\n",
        "    soup = makeSoup(startURL + str(pageNumber))\n",
        "    getCurrentPageLinks(soup, links)\n",
        "    pageNumber +=1\n",
        "\n",
        "    ## TEST\n",
        "    if(pageNumber == limit+1):\n",
        "      break;\n",
        "\n",
        "def getCurrentPageLinks(soupList, linksQA):\n",
        "    h3 = soupList.select(\".ecl-list-item__link\")\n",
        "    for heading in h3:\n",
        "        linksQA.append(baseURL + heading[\"href\"])\n",
        "\n",
        "# MAIN2: Kalei getQA apo ola ta links sigkekrimenou page\n",
        "def downloadLinkInfo(links):\n",
        "  page = 0\n",
        "  for link in links:\n",
        "    page+=1\n",
        "    print(page)\n",
        "\n",
        "    soupLink = makeSoup(link)\n",
        "    getQA(soupLink, link)\n",
        "\n",
        "# GET QA kai MetaInfo kathe Selidas sigkekrimenhs (r)\n",
        "def getQA(soupQA, link):\n",
        "  section = soupQA.select(\"#inline-nav-1\")[0]   # select() epistrefei [] - ResultSet me tags\n",
        "  findQuestions(section)\n",
        "  pageInfo = getMetaInfo(soupQA)\n",
        "\n",
        "  strippedSection = stripSection(section)\n",
        "  answerMatches = re.findall(pattern, strippedSection)\n",
        "  # Edw soupQA_section + \"<question>\"\n",
        "  # print(answerMatches[-1])\n",
        "  questions = soupQA.select(\"question\")\n",
        "  # print(len(answerMatches))\n",
        "\n",
        "  if (len(questions) <= 1):\n",
        "    print(link)\n",
        "    print(\"Error: One or zero questions found\")\n",
        "    if (len(questions) == 0):\n",
        "      return\n",
        "  if len(answerMatches) != len(questions):\n",
        "    print(link)\n",
        "    print(len(questions))\n",
        "    print(len(answerMatches))\n",
        "  print()\n",
        "\n",
        "  questionsText = []\n",
        "  for question in questions:\n",
        "    questionsText.append(question.get_text().strip())\n",
        "\n",
        "  embeddingArray = makeEmbedding(questionsText, retrieverEmbedding)\n",
        "\n",
        "  QA_Array = makeQA_Array(answerMatches, questionsText, pageInfo, embeddingArray)\n",
        "  updateHaystack(document_store,QA_Array)\n",
        "\n",
        "def stripSection(section):\n",
        "  if str(section)[-16:]!=\"</div></section>\":        #</div></section>\n",
        "    print(\"no\")\n",
        "  return (str(section)[:-16] + \"<question>\")\n",
        "\n",
        "def updateHaystack(document_store, QA_Array):\n",
        "  document_store.write_documents(QA_Array)\n",
        "\n",
        "# Pairnei Question, Answer, Embedding, MetaInfo apo kathena kai -> [dicts]\n",
        "def makeQA_Array(answerArray, questions, pageInfo, embeddingArray):       # prosthetw metaInfo\n",
        "  QA_Array = []\n",
        "  index = 0\n",
        "  for answer in answerArray:\n",
        "    questionObject = {}\n",
        "    questionObject[\"content\"] = questions[index]\n",
        "    questionObject[\"question_emb\"] = embeddingArray[index]\n",
        "    # questionObject[\"question_emb\"] = list(map(lambda x:0, embeddingArray))\n",
        "    questionObject[\"answer\"] = answer\n",
        "    questionObject[\"title\"] = pageInfo[\"title\"]\n",
        "    questionObject[\"date\"] = pageInfo[\"date\"]\n",
        "    questionObject[\"country\"] = pageInfo[\"country\"]\n",
        "\n",
        "    QA_Array.append(questionObject)\n",
        "    index += 1\n",
        "  return QA_Array\n",
        "\n",
        "# Make Embedding apo lista Questions\n",
        "def makeEmbedding(questionsList, retrieverEmbedding):\n",
        "  embeddingArray = retrieverEmbedding.embed_queries(texts=questionsList)\n",
        "  return embeddingArray\n",
        "\n",
        "def isNotOrderListStyle(section):\n",
        "  if section.div.contents[0].name == \"ol\" or section.div.contents[0].name == \"ul\":\n",
        "    firstElement = section.div.contents[0].contents[0]\n",
        "    if firstElement.strip() == \"\":\n",
        "      firstElement = firstElement.parent.contents[1]\n",
        "  else:\n",
        "    firstElement = section.div.contents[0]\n",
        "  if isQuestion(firstElement):\n",
        "    return (section.div.contents[0].name == \"p\")\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "def isQuestion(textElement):\n",
        "  pText = textElement.get_text().strip()\n",
        "  # print(pText)\n",
        "  if textElement.parent:\n",
        "    if pText == textElement.parent.get_text().strip() and len(pText)!=0 and pText[-1].strip() == \"?\":\n",
        "      return True\n",
        "\n",
        "    siblingNumber = len(textElement.parent.contents) -1\n",
        "    siblings = []\n",
        "\n",
        "    if siblingNumber >=1 and textElement.parent.contents[0].name==\"strong\":\n",
        "      if textElement == textElement.parent.contents[0]:\n",
        "        strongText = textElement.get_text()\n",
        "        if siblingNumber <= 4:\n",
        "          for i in range(siblingNumber):\n",
        "            siblings.append(textElement.parent.contents[i+1])\n",
        "            if textElement.parent.contents[i+1].name==\"strong\":\n",
        "              strongText = strongText + \" \" + textElement.parent.contents[i+1].get_text()\n",
        "          strongText.strip()\n",
        "        \n",
        "        if len(strongText)!=0 and strongText == textElement.parent.get_text().strip() and strongText[-1].strip()==\"?\":\n",
        "          textElement.clear()\n",
        "          textElement.append(strongText)\n",
        "          for sibling in siblings:\n",
        "            sibling.extract()\n",
        "          # print(textElement)\n",
        "          return True\n",
        "  return False\n",
        "def findQuestions(section):\n",
        "  if (isNotOrderListStyle(section)):\n",
        "    if (section.div.contents[0].name == \"p\"):\n",
        "      qa = section.select(\"p strong\")\n",
        "    else:\n",
        "      qa = section.select(\"h3\")\n",
        "      for h3 in qa:\n",
        "        h3.name = \"question\"\n",
        "        # print(h3.get_text())\n",
        "      return\n",
        "  else:\n",
        "    qa = section.select(\"ol li strong\")\n",
        "\n",
        "  qNumber = 0\n",
        "  for paragraph in qa:\n",
        "    if isQuestion(paragraph):\n",
        "      paragraph.name = \"question\"\n",
        "      qNumber += 1\n",
        "      # print(paragraph.get_text())\n",
        "    else:\n",
        "      continue\n",
        "def getMetaInfo(soupLink):\n",
        "  title = soupLink.h1.get_text()\n",
        "  metaInfo = soupLink.select(\"span.ecl-meta__item\")[1:]\n",
        "  pageInfo = {\"title\": title, \"date\": metaInfo[0].get_text(), \"country\": metaInfo[1].get_text()}\n",
        "  return pageInfo\n",
        "\n",
        "def pipeRun(isEmbedding, query):\n",
        "  if isEmbedding:\n",
        "    prediction = pipeEmbedding.run(query=query, params={\"Retriever\":{\"top_k\": 5}})\n",
        "  else:\n",
        "    prediction = pipeElastic.run(query=query, params={\"Retriever\":{\"top_k\": 5}})\n",
        "  # print(prediction[\"answers\"])        # [\"answers\"][0]\n",
        "  resultsList=[]\n",
        "  for answer in prediction[\"answers\"]:\n",
        "    result = {}\n",
        "    result[\"meta\"] = answer.meta\n",
        "    result[\"score\"] = answer.score\n",
        "    resultsList.append(result)\n",
        "  resultsDict = {\"answerList\": resultsList, \"query\": prediction[\"query\"]}\n",
        "  return resultsDict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run program για να γεμίσουμε haystack-document_store"
      ],
      "metadata": {
        "id": "kFab4XWNOcSZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s1MOWKBQ7wh"
      },
      "outputs": [],
      "source": [
        "## RUN ##\n",
        "\n",
        "links = []\n",
        "anakthsh(links, 60)        # findAllPageLinks\n",
        "\n",
        "# pipeRun(False, \"Europe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web-server \n",
        "#### Flask server running with ngrok"
      ],
      "metadata": {
        "id": "cdJKVzLGOqiz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tDqtAKToP3g"
      },
      "outputs": [],
      "source": [
        "import urllib.parse\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "  \n",
        "app = Flask(__name__, template_folder=\"./Anakthsh/templates\", static_folder=\"./Anakthsh/static\")\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"formApp.html\")\n",
        "\n",
        "@app.route(\"/elastic/<encodedQuery>\")\n",
        "def elasticSearch(encodedQuery):\n",
        "    #trexe to piperun me to query\n",
        "    query = urllib.parse.unquote(encodedQuery)\n",
        "    elastic_results = pipeRun(False, query )\n",
        "    return elastic_results\n",
        "\n",
        "@app.route(\"/embedding/<encodedQuery>\")\n",
        "def embeddingSearch(encodedQuery):\n",
        "    #trexe to piperun me to query\n",
        "    query = urllib.parse.unquote(encodedQuery)    \n",
        "    embedding_results = pipeRun(True, query )\n",
        "    return embedding_results\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "##Πιθανά προβλήματα"
      ],
      "metadata": {
        "id": "jjqgr_bGQDEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxRetryError: HTTPConnectionPool(host='localhost', port=60151): Max retries exceeded with url: /session/<> (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe7a900df90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
        "\n",
        "<b>Λύση: Ξαναφτιάχνω chrome-browser της selenium"
      ],
      "metadata": {
        "id": "AMw7bLq5qiZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIGhflLudBKu"
      },
      "outputs": [],
      "source": [
        "# chrome_options = webdriver.ChromeOptions()\n",
        "# chrome_options.add_argument('--headless')\n",
        "# chrome_options.add_argument('--no-sandbox')\n",
        "# chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# browser = webdriver.Chrome('chromedriver',options=chrome_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WARNING - elasticsearch -  POST http://localhost:9200/_bulk?refresh=wait_for [status:N/A request:0.001s]\n",
        "Traceback (most recent call last):\n",
        "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 160, in _new_conn\n",
        "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
        "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
        "    raise err\n",
        "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
        "    sock.connect(sa)\n",
        "ConnectionRefusedError: [Errno 111] Connection refused\n",
        "\n",
        "<b>Λύση: Ξανατρέχω τον elasticsearch server"
      ],
      "metadata": {
        "id": "MDOzJ1ISrGNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from subprocess import Popen,PIPE,STDOUT\n",
        "\n",
        "# es_server = Popen(\n",
        "#     [\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1)\n",
        "# )\n",
        "# !sleep 30"
      ],
      "metadata": {
        "id": "apF4W62NrBqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bALLfMZgd-fk"
      },
      "source": [
        "### Commented out tests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ##TESTS\n",
        "# #downloadLinkInfo\n",
        "# downloadLinkInfo(links)\n",
        "\n",
        "# #getQA\n",
        "# getQA(makeSoup(\"https://ec.europa.eu/commission/presscorner/detail/en/qanda_21_6621\"), 3)\n",
        "\n",
        "# #makeEmbedding\n",
        "# soup = makeSoup(\"https://ec.europa.eu/commission/presscorner/detail/en/qanda_22_2322\")\n",
        "# findQuestions(soup)\n",
        "# questions = soup.select(\"question\")     # thelei get_text()\n",
        "# questionsText = []\n",
        "# for question in questions:\n",
        "#   questionsText.append(question.get_text().strip())\n",
        "# questions = questions.apply(lambda x: x.get_text.strip())\n",
        "# makeEmbedding(questionsText, retrieverEmbedding)\n",
        "\n",
        "# #isNotOrderListStyle\n",
        "# for link in links[3]:\n",
        "#   soup = makeSoup(\"https://ec.europa.eu/commission/presscorner/detail/en/qanda_21_6093\")\n",
        "#   section = soup.select(\"#inline-nav-1\")[0]\n",
        "#   print(isNotOrderListStyle(section))\n",
        "\n",
        "# #isQuestion\n",
        "# soupSection = makeSoup(\"https://ec.europa.eu/commission/presscorner/detail/en/qanda_22_2004\").select(\"#inline-nav-1\")[0]\n",
        "# question = soupSection.select(\"p strong\")[0]\n",
        "# isQuestion(question)\n",
        "\n",
        "# #findQuestions\n",
        "# sectionTest = makeSoup(\"https://ec.europa.eu/commission/presscorner/detail/en/qanda_22_2004\").select(\"#inline-nav-1\")[0]\n",
        "# print(isNotOrderListStyle(sectionTest))\n",
        "# findQuestions(sectionTest)\n",
        "\n",
        "# #getMetaInfo\n",
        "# getMetaInfo(makeSoup(\"https://ec.europa.eu/commission/presscorner/detail/en/qanda_22_2322\"))"
      ],
      "metadata": {
        "id": "koLFQgnuzuZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bALLfMZgd-fk"
      ],
      "name": "Anakthsh_git.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMx3hk6tuKpL4q8pXapgtUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}